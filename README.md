## EDW-2 Snowflake Reasoning Assistant

The EDW-2 Reasoning Assistant is a Snowflake-native analytical and AI reasoning system designed to analyze enterprise revenue data, generate structured evidence, and produce business-grade explanations using Snowflake Cortex.

This project is the evolution of an earlier Google Colab prototype, fully rebuilt on Snowflake to achieve:
	â€¢	Warehouse-level scalability
	â€¢	Secure, governed data execution
	â€¢	Native Streamlit UX
	â€¢	LLM-driven reasoning inside the data platform

The system integrates SQL models, Snowpark Python, Cortex LLMs, and an agentic reasoning pipeline to answer business questions over structured data.

â¸»

# ğŸ“Œ Authors
	â€¢	Mehjabeen T Shaik
	â€¢	Myles Green
	â€¢	Sherin Kiruba Prem Anand
	â€¢	Jeevith Doddalingegowda Rama

â¸»

# ğŸ“Œ Features

1. Snowflake-Native Data Models

All analytics are computed dynamically using Snowflake SQL views:
	â€¢	V_REVENUE_BY_QUARTER
	â€¢	V_REVENUE_BY_REGION
	â€¢	V_REVENUE_BY_PRODUCT

These views derive key metrics:
	â€¢	Total Revenue
	â€¢	Total Cost
	â€¢	Total Profit

and power the reasoning pipeline.

â¸»

2. Snowpark-Driven Analytics

The Streamlit app fetches view results using Snowpark:

    rev = session.sql("SELECT * FROM ...").to_pandas()

This ensures:
	â€¢	zero external compute
	â€¢	secure, in-warehouse execution
	â€¢	low-latency analysis

â¸»

3. Agentic LLM Reasoning Pipeline

The reasoning system includes four core agents:

Router
Classifies the incoming question as:
	â€¢	simple â†’ requires no planning
	â€¢	reasoning â†’ requires multistep analysis

Planner
Uses Cortex LLM to generate:
	â€¢	sub-questions
	â€¢	a structured JSON reasoning plan tied to quarter/region/product analytics

Executor
Runs Snowflake analytics based on the plan:
	â€¢	fetches relevant SQL views
	â€¢	builds structured evidence objects

Synthesizer
Calls Cortex again with:
	â€¢	the user question
	â€¢	the generated plan
	â€¢	the evidence

and returns a polished, multi-paragraph business explanation.

â¸»

4. Automated Sub-Question Generation

For reasoning queries, the system calls Cortex to generate clarifying sub-questions that help shape the plan.

These appear in the UI for transparency.

â¸»

5. Simple Question Mode

If the query is straightforward (e.g., â€œWhich product had the most revenue last quarter?â€):
	â€¢	the router skips planning
	â€¢	evidence is passed directly to Cortex
	â€¢	the model produces a concise factual answer

This ensures efficiency and prevents unnecessary reasoning overhead.

â¸»

6. Snowflake Streamlit Application

The entire application runs inside Snowflake, providing:
	â€¢	question input
	â€¢	sub-question display
	â€¢	plan visualization
	â€¢	data previews (quarter/region/product)
	â€¢	final AI explanation

All compute occurs in-warehouse.

â¸»

# ğŸ“‚ Project Structure

app/
â”‚
â”œâ”€â”€ config.py            # Global configuration (models, constants, metadata)
â”œâ”€â”€ session.py           # Snowflake Snowpark session helpers
â”œâ”€â”€ analytics.py         # Fetch quarter/region/product analytics via Snowpark
â”œâ”€â”€ routing.py           # classify_question() â†’ simple vs reasoning
â”œâ”€â”€ planning.py          # Generate subquestions + LLM-driven planning
â”œâ”€â”€ evidence.py          # Build structured evidence objects
â”œâ”€â”€ reasoning.py         # Synthesize final explanation (Cortex)
â”œâ”€â”€ cortex_client.py     # Wrapper for SNOWFLAKE.CORTEX.COMPLETE
â””â”€â”€ __init__.py
â”‚
streamlit_app.py         # Main Snowflake Streamlit application
sql/
â”‚   â”œâ”€â”€ create_schema.sql
â”‚   â”œâ”€â”€ mock_data_inserts.sql
â”‚   â””â”€â”€ views.sql
README.md


â¸»

# ğŸš€ How It Works (High-Level Workflow)
	1.	User submits a business question
	2.	Router classifies it as simple or reasoning
	3.	If reasoning:
	â€¢	LLM generates sub-questions
	â€¢	LLM generates a multi-step JSON plan
	4.	Executor runs analytics views based on the plan
	5.	Evidence is packaged into structured JSON
	6.	Synthesizer calls Cortex to generate the final narrative explanation
	7.	UI displays:
	â€¢	sub-questions
	â€¢	plan
	â€¢	evidence previews
	â€¢	final explanation

â¸»

# ğŸ§  Cortex LLM Integration

Cortex is used in three places:
	1.	Sub-question generation
	2.	Planning (JSON step generation)
	3.	Final reasoning synthesis

The system uses:
	â€¢	SNOWFLAKE.CORTEX.COMPLETE
	â€¢	Model: snowflake-arctic (or any allowed LLM)

All prompts are securely escaped for SQL execution.

â¸»

# ğŸ—„ï¸ Data Layer (SQL Models)

Your SQL models:
	â€¢	auto-compute revenue metrics
	â€¢	eliminate redundant logic
	â€¢	offer consistent inputs to the LLM reasoning chain

This design supports future expansion: forecasts, anomalies, cost-driver analysis, etc.

â¸»

# ğŸ§ª Development Challenges Resolved
	â€¢	Git integration and conflicts
	â€¢	Snowflake schema mismatches (PUBLIC vs REASONING)
	â€¢	Warehouse suspension issues
	â€¢	Import path problems inside Snowflake UDF containers
	â€¢	Cortex model availability errors

All were resolved through schema standardization, better SQL organization, and code restructuring.

â¸»

# âœ” Final Capabilities

The EDW-2 Reasoning Assistant now:
	â€¢	answers business questions in natural language
	â€¢	performs root-cause revenue analysis
	â€¢	dynamically creates multi-step reasoning plans
	â€¢	surfaces structured evidence
	â€¢	runs entirely inside Snowflake
	â€¢	provides enterprise-grade scalability and governance

â¸»

# ğŸ“¥ Deployment Instructions

Upload to Snowflake Git Integration
	1.	Create a new Snowflake Git repository mapping
	2.	Upload the project folder structure as-is
	3.	Ensure the following files appear in Git:

streamlit_app.py
app/*
sql/*

Create Streamlit App

In Snowflake UI:
	1.	Navigate to Projects â†’ Streamlit
	2.	Create new app
	3.	Point to: <repo>/streamlit_app.py
	4.	Set execution role: ACCOUNTADMIN (or a custom role with SELECT + USAGE on EDW_2_DB.REASONING)
	5.	Select warehouse: EDW_COMPUTE_WH

The app will launch immediately.

â¸»

# ğŸ“„ License

Enterprise demonstration project â€” internal use only.

â¸»